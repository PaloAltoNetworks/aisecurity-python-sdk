# Copyright (c) 2025, Palo Alto Networks
#
# Licensed under the Polyform Internal Use License 1.0.0 (the "License");
# you may not use this file except in compliance with the License.
#
# You may obtain a copy of the License at:
#
# https://polyformproject.org/licenses/internal-use/1.0.0
# (or)
# https://github.com/polyformproject/polyform-licenses/blob/76a278c4/PolyForm-Internal-Use-1.0.0.md
#
# As far as the law allows, the software comes as is, without any warranty
# or condition, and the licensor will not be liable to you for any damages
# arising out of these terms or the use or nature of the software, under
# any kind of legal claim.

"""
AISec API service

OpenAPI Specification for the AI Runtime Security API service

The version of the OpenAPI document: 0.0.0
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501

import unittest

from aisecurity.generated_openapi_client.models.scan_response import ScanResponse


class TestScanResponse(unittest.TestCase):
    """ScanResponse unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> ScanResponse:
        """Test ScanResponse
        include_optional is a boolean, when False only required
        params are included, when True both required and
        optional params are included"""
        # uncomment below to create an instance of `ScanResponse`
        """
        model = ScanResponse()
        if include_optional:
            return ScanResponse(
                source = '',
                report_id = '',
                scan_id = '',
                tr_id = '',
                session_id = '',
                profile_id = '',
                profile_name = '',
                category = '',
                action = '',
                prompt_detected = aisecurity.generated_openapi_client.models.prompt_detected.PromptDetected(
                    url_cats = True,
                    dlp = True,
                    injection = True,
                    toxic_content = True,
                    malicious_code = True,
                    agent = True,
                    topic_violation = True, ),
                response_detected = aisecurity.generated_openapi_client.models.response_detected.ResponseDetected(
                    url_cats = True,
                    dlp = True,
                    db_security = True,
                    toxic_content = True,
                    malicious_code = True,
                    agent = True,
                    ungrounded = True,
                    topic_violation = True, ),
                prompt_masked_data = aisecurity.generated_openapi_client.models.masked_data.MaskedData(
                    data = '',
                    pattern_detections = [
                        aisecurity.generated_openapi_client.models.pattern_detections.PatternDetections(
                            pattern = '',
                            locations = [
                                [
                                    56
                                    ]
                                ], )
                        ], ),
                response_masked_data = aisecurity.generated_openapi_client.models.masked_data.MaskedData(
                    data = '',
                    pattern_detections = [
                        aisecurity.generated_openapi_client.models.pattern_detections.PatternDetections(
                            pattern = '',
                            locations = [
                                [
                                    56
                                    ]
                                ], )
                        ], ),
                prompt_detection_details = aisecurity.generated_openapi_client.models.prompt_detection_details.PromptDetectionDetails(
                    topic_guardrails_details = aisecurity.generated_openapi_client.models.topic_guard_rails.TopicGuardRails(
                        allowed_topics = [
                            ''
                            ],
                        blocked_topics = [
                            ''
                            ], ), ),
                response_detection_details = aisecurity.generated_openapi_client.models.response_detection_details.ResponseDetectionDetails(
                    topic_guardrails_details = aisecurity.generated_openapi_client.models.topic_guard_rails.TopicGuardRails(
                        allowed_topics = [
                            ''
                            ],
                        blocked_topics = [
                            ''
                            ], ), ),
                tool_detected = aisecurity.generated_openapi_client.models.tool_detected.ToolDetected(
                    verdict = 'malicious',
                    metadata = aisecurity.generated_openapi_client.models.tool_event_metadata.ToolEventMetadata(
                        ecosystem = 'mcp',
                        method = 'tools/call',
                        server_name = 'MCP server',
                        tool_invoked = 'get_file', ),
                    summary = aisecurity.generated_openapi_client.models.scan_summary.ScanSummary(
                        detections = aisecurity.generated_openapi_client.models.tool_detection_flags.ToolDetectionFlags(
                            injection = True,
                            url_cats = True,
                            dlp = True,
                            db_security = True,
                            toxic_content = True,
                            malicious_code = True,
                            agent = True,
                            topic_violation = True, ),
                        threats = ["credential leakage","context poisoning"], ),
                    input_detected = aisecurity.generated_openapi_client.models.io_detected.IODetected(
                        detection_entries = [
                            aisecurity.generated_openapi_client.models.tool_detection_entry.ToolDetectionEntry(
                                tool_invoked = 'get_file',
                                threats = ["credential leakage","context poisoning"],
                                details = aisecurity.generated_openapi_client.models.tool_detection_details.ToolDetectionDetails(
                                    topic_guardrails_details = aisecurity.generated_openapi_client.models.topic_guard_rails.TopicGuardRails(
                                        allowed_topics = [
                                            ''
                                            ],
                                        blocked_topics = [
                                            ''
                                            ], ), ),
                                masked_data = aisecurity.generated_openapi_client.models.masked_data.MaskedData(
                                    data = '',
                                    pattern_detections = [
                                        aisecurity.generated_openapi_client.models.pattern_detections.PatternDetections(
                                            pattern = '',
                                            locations = [
                                                [
                                                    56
                                                    ]
                                                ], )
                                        ], ), )
                            ], ),
                    output_detected = aisecurity.generated_openapi_client.models.io_detected.IODetected(), ),
                created_at = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'),
                completed_at = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f')
            )
        else:
            return ScanResponse(
                report_id = '',
                scan_id = '',
                category = '',
                action = '',
        )
        """

    def testScanResponse(self):
        """Test ScanResponse"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)


if __name__ == "__main__":
    unittest.main()
