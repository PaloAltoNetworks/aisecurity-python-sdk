# Copyright (c) 2025, Palo Alto Networks
#
# Licensed under the Polyform Internal Use License 1.0.0 (the "License");
# you may not use this file except in compliance with the License.
#
# You may obtain a copy of the License at:
#
# https://polyformproject.org/licenses/internal-use/1.0.0
# (or)
# https://github.com/polyformproject/polyform-licenses/blob/76a278c4/PolyForm-Internal-Use-1.0.0.md
#
# As far as the law allows, the software comes as is, without any warranty
# or condition, and the licensor will not be liable to you for any damages
# arising out of these terms or the use or nature of the software, under
# any kind of legal claim.

"""
AISec API service

OpenAPI Specification for the AI Runtime Security API service

The version of the OpenAPI document: 0.0.0
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501

import unittest

from aisecurity.generated_openapi_client.models.tool_detection_entry import ToolDetectionEntry


class TestToolDetectionEntry(unittest.TestCase):
    """ToolDetectionEntry unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> ToolDetectionEntry:
        """Test ToolDetectionEntry
        include_optional is a boolean, when False only required
        params are included, when True both required and
        optional params are included"""
        # uncomment below to create an instance of `ToolDetectionEntry`
        """
        model = ToolDetectionEntry()
        if include_optional:
            return ToolDetectionEntry(
                tool_invoked = 'get_file',
                detections = aisecurity.generated_openapi_client.models.tool_detection_flags.ToolDetectionFlags(
                    injection = True,
                    url_cats = True,
                    dlp = True,
                    db_security = True,
                    toxic_content = True,
                    malicious_code = True,
                    agent = True,
                    topic_violation = True, ),
                threats = ["credential leakage","context poisoning"],
                details = aisecurity.generated_openapi_client.models.tool_detection_details.ToolDetectionDetails(
                    topic_guardrails_details = aisecurity.generated_openapi_client.models.topic_guard_rails.TopicGuardRails(
                        allowed_topics = [
                            ''
                            ],
                        blocked_topics = [
                            ''
                            ], ), ),
                masked_data = aisecurity.generated_openapi_client.models.masked_data.MaskedData(
                    data = '',
                    pattern_detections = [
                        aisecurity.generated_openapi_client.models.pattern_detections.PatternDetections(
                            pattern = '',
                            locations = [
                                [
                                    56
                                    ]
                                ], )
                        ], )
            )
        else:
            return ToolDetectionEntry(
        )
        """

    def testToolDetectionEntry(self):
        """Test ToolDetectionEntry"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)


if __name__ == "__main__":
    unittest.main()
